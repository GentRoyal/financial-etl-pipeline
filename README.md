# ğŸ“ˆ Stock ETL and Prediction Pipeline

This project is an end-to-end stock market prediction system that automates data extraction, transformation, model training, and prediction delivery. It is powered by AlphaVantage, FastAPI, MLflow, Docker, and GitHub Actions â€” and is **live on an AWS EC2 instance**.

---

## ğŸŒ Live Demo

**ğŸ”— API Base URL:** `http://13.60.179.140/`
**ğŸ“˜ Swagger Docs:** `http://13.60.179.140/docs`

---

## ğŸš€ Key Features

* âœ… **ETL pipeline** to fetch and process stock data via AlphaVantage
* âœ… **170+ technical indicators** with statistical feature selection (41 selected)
* âœ… **MLPClassifier model** for binary stock movement prediction
* âœ… **FastAPI** server for real-time prediction and historical data access
* âœ… **MLflow** for experiment tracking and model versioning
* âœ… **Dockerized** for easy deployment
* âœ… **CI/CD** with GitHub Actions
* âœ… **Deployed** and running on AWS EC2

---

## ğŸ—‚ï¸ Project Structure

```
stock-etl-pipeline/
â”‚
â”œâ”€â”€ app/                  # FastAPI app logic
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ models/  #Saved Models
â”‚   â”œâ”€â”€ mlruns/  # MLflow tracking
â”‚   â”œâ”€â”€ data/
â”‚   â”‚    â”œâ”€â”€ raw/ #Raw Dataset
â”‚   â”‚    â”œâ”€â”€ processed/ #Dataset after feature engineering 
â”‚   â”‚    â”œâ”€â”€ results/ # Model Training Results 
â”‚   â”‚     
â”‚   â””â”€â”€ scripts/
â”‚        â”œâ”€â”€api_data_fetcher.py/                  # ETL scripts
â”‚        â”œâ”€â”€ config.py
â”‚        â”œâ”€â”€ database_handler.py
â”‚        â”œâ”€â”€ feature_engineering.py
â”‚        â”œâ”€â”€ model_trainer.py
â”‚        â””â”€â”€ statistical_measures.py
â”‚
â”œâ”€â”€ .github/workflows/    # CI/CD configs
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Local Development (Optional)

1. **Clone the repo**

```bash
git clone https://github.com/your-username/stock-etl-pipeline.git
cd stock-etl-pipeline
```

2. **Set environment variable**

Create a `v.env` file with your API key from AlphaVantage:

```
API_KEY="your_key_here"
DB_NAME="data.sqlite"
MODEL_DIR="models"
```

3. **Build and run Docker containers**

```bash
docker-compose up --build
```

4. **Access API locally**

Go to [http://localhost:8000/docs](http://localhost:8000/docs)

---

## ğŸ§  Model Details

* **Type**: MLPClassifier (Multi-layer perceptron)
* **Input**: 41 selected technical indicators
* **Output**: Up or Down stock movement
* **Training Pipeline**: Includes feature scaling, selection, and resampling (if needed)
* **Tracking**: Experiments tracked using MLflow

---

## ğŸ”„ CI/CD Workflow

* GitHub Actions runs linting, testing, and Docker build on push
* Deployment handled via SSH to EC2 or Docker Compose on server
* ML models are versioned and logged via MLflow

---

## ğŸ“¦ API Endpoints

* `POST /historical_prediction/` â€“ Make Predictions Based on Existing Data
* `POST /predict_stock_directions/` â€“ Get Prediction for Input Features
* `POST /load_data_from_api/` â€“ Get data from AlphaVantage
* `GET /docs` â€“ Interactive API Documentation (Swagger UI)
* `GET /model_accuracy` â€“ Get Model Accuracy

---

## ğŸ›  Technologies Used

* Python Â· FastAPI Â· Scikit-learn Â· MLflow Â· Docker Â· GitHub Actions Â· AWS EC2 Â· AlphaVantage API

---

## âœï¸ Author

**Ridwan Yusuf: Data Scientist | Exploring MLOps**

[Medium Articles](https://medium.com/@gentroyal) | [LinkedIn](https://www.linkedin.com/in/yusufridwan/)